{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo2gC5uS4-Ws",
        "outputId": "d66d13f9-e25c-4f4d-9943-18fa0573ac72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mean weight change per update: 0.000000\n",
            "✅ Initial CVaR: 0.0139, Final CVaR: 0.0139\n",
            "✅ Approx gradient norm: 0.000000\n",
            "✅ All improved tests completed successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# Explicit projection onto probability simplex\n",
        "# -------------------------------\n",
        "def project_simplex(w):\n",
        "    \"\"\"Projects a vector onto the probability simplex.\"\"\"\n",
        "    w = np.maximum(w, 1e-5)\n",
        "    w /= np.sum(w)\n",
        "    return w\n",
        "\n",
        "# -------------------------------\n",
        "# Hilbert-enhanced CVaR update (vector-based)\n",
        "# -------------------------------\n",
        "def hilbert_cvar_update(weights, asset_returns, alpha=0.05):\n",
        "    \"\"\"\n",
        "    CVaR-adjusted update with asset-level vector risk consideration and explicit projection.\n",
        "    \"\"\"\n",
        "    losses = -asset_returns\n",
        "    var = np.percentile(losses, 100 * (1 - alpha))\n",
        "    cvar = losses[losses >= var].mean()\n",
        "    adj = np.exp(-cvar)\n",
        "\n",
        "    new_w = weights * adj\n",
        "    new_w = project_simplex(new_w)\n",
        "\n",
        "    return new_w\n",
        "\n",
        "# -------------------------------\n",
        "# Tests\n",
        "# -------------------------------\n",
        "def test_projection(weights):\n",
        "    assert np.isclose(np.sum(weights), 1.0, atol=1e-6), \"Weights do not sum to 1\"\n",
        "    assert np.all(weights >= 0), \"Negative weights found\"\n",
        "\n",
        "def test_convergence(weights_history):\n",
        "    diffs = np.abs(np.diff(weights_history, axis=0))\n",
        "    mean_change = np.mean(diffs)\n",
        "    print(f\"✅ Mean weight change per update: {mean_change:.6f}\")\n",
        "\n",
        "def test_cvar_reduction(returns, weights_initial, weights_final, alpha=0.05):\n",
        "    port_ret_initial = returns @ weights_initial\n",
        "    port_ret_final = returns @ weights_final\n",
        "\n",
        "    losses_initial = -port_ret_initial\n",
        "    losses_final = -port_ret_final\n",
        "\n",
        "    var_init = np.percentile(losses_initial, 100 * (1 - alpha))\n",
        "    var_final = np.percentile(losses_final, 100 * (1 - alpha))\n",
        "\n",
        "    cvar_init = losses_initial[losses_initial >= var_init].mean()\n",
        "    cvar_final = losses_final[losses_final >= var_final].mean()\n",
        "\n",
        "    print(f\"✅ Initial CVaR: {cvar_init:.4f}, Final CVaR: {cvar_final:.4f}\")\n",
        "\n",
        "def test_smoothness(weights, returns, eps=1e-5):\n",
        "    base_value = hilbert_cvar_update(weights, returns)\n",
        "    perturbed_weights = weights + eps\n",
        "    perturbed_weights = project_simplex(perturbed_weights)\n",
        "    pert_value = hilbert_cvar_update(perturbed_weights, returns)\n",
        "    grad_norm = np.linalg.norm(pert_value - base_value) / eps\n",
        "    print(f\"✅ Approx gradient norm: {grad_norm:.6f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Simulation setup\n",
        "# -------------------------------\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range(\"2010-01-01\", periods=2520, freq='B')\n",
        "assets = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]\n",
        "returns_df = pd.DataFrame(0.001 + 0.02 * np.random.randn(len(dates), len(assets)), index=dates, columns=assets)\n",
        "\n",
        "weights = np.ones(len(assets)) / len(assets)\n",
        "weights_history = []\n",
        "\n",
        "for t in range(60, len(returns_df)):\n",
        "    asset_returns = returns_df.iloc[t].values  # Now using full vector\n",
        "    adj_weights = hilbert_cvar_update(weights, asset_returns)\n",
        "    weights = adj_weights\n",
        "    weights_history.append(weights)\n",
        "\n",
        "weights_history = np.array(weights_history)\n",
        "\n",
        "# -------------------------------\n",
        "# Run tests\n",
        "# -------------------------------\n",
        "test_projection(weights_history[-1])\n",
        "test_convergence(weights_history)\n",
        "test_cvar_reduction(returns_df.iloc[-100:].values, np.ones(len(assets)) / len(assets), weights_history[-1])\n",
        "test_smoothness(weights, returns_df.iloc[-1].values)\n",
        "\n",
        "print(\"✅ All improved tests completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# Explicit projection operator\n",
        "# -------------------------------\n",
        "def project_simplex(w):\n",
        "    w = np.maximum(w, 1e-5)\n",
        "    w /= np.sum(w)\n",
        "    return w\n",
        "\n",
        "# -------------------------------\n",
        "# Hilbert-enhanced CVaR update\n",
        "# -------------------------------\n",
        "def hilbert_cvar_update(weights, asset_returns, alpha=0.05):\n",
        "    losses = -asset_returns\n",
        "    var = np.percentile(losses, 100 * (1 - alpha))\n",
        "    cvar = losses[losses >= var].mean()\n",
        "    adj = np.exp(-cvar)\n",
        "    new_w = weights * adj\n",
        "    new_w = project_simplex(new_w)\n",
        "    return new_w\n",
        "\n",
        "# -------------------------------\n",
        "# Tests\n",
        "# -------------------------------\n",
        "def test_projection(weights):\n",
        "    assert np.isclose(np.sum(weights), 1.0, atol=1e-6), \"Weights do not sum to 1\"\n",
        "    assert np.all(weights >= 0), \"Negative weights found\"\n",
        "\n",
        "def test_convergence(weights_history):\n",
        "    diffs = np.abs(np.diff(weights_history, axis=0))\n",
        "    mean_change = np.mean(diffs)\n",
        "    print(f\"✅ Mean weight change per update: {mean_change:.6f}\")\n",
        "\n",
        "def test_cvar_reduction(returns, weights_initial, weights_final, alpha=0.05):\n",
        "    port_ret_initial = returns @ weights_initial\n",
        "    port_ret_final = returns @ weights_final\n",
        "    losses_initial = -port_ret_initial\n",
        "    losses_final = -port_ret_final\n",
        "    var_init = np.percentile(losses_initial, 100 * (1 - alpha))\n",
        "    var_final = np.percentile(losses_final, 100 * (1 - alpha))\n",
        "    cvar_init = losses_initial[losses_initial >= var_init].mean()\n",
        "    cvar_final = losses_final[losses_final >= var_final].mean()\n",
        "    print(f\"✅ Initial CVaR: {cvar_init:.4f}, Final CVaR: {cvar_final:.4f}\")\n",
        "\n",
        "def test_smoothness(weights, returns, eps=1e-5):\n",
        "    base_value = hilbert_cvar_update(weights, returns)\n",
        "    perturbed_weights = weights + eps\n",
        "    perturbed_weights = project_simplex(perturbed_weights)\n",
        "    pert_value = hilbert_cvar_update(perturbed_weights, returns)\n",
        "    grad_norm = np.linalg.norm(pert_value - base_value) / eps\n",
        "    print(f\"✅ Approx gradient norm: {grad_norm:.6f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Heavy-tail & shock simulation\n",
        "# -------------------------------\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range(\"2010-01-01\", periods=2520, freq='B')\n",
        "assets = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]\n",
        "\n",
        "# Simulate t-distributed returns (df=3 for heavy tails)\n",
        "returns_arr = 0.001 + 0.03 * np.random.standard_t(df=3, size=(len(dates), len(assets)))\n",
        "\n",
        "# Crisis shocks: inject big negative returns on random days\n",
        "shock_days = np.random.choice(len(dates), size=10, replace=False)\n",
        "for day in shock_days:\n",
        "    returns_arr[day] -= 0.2  # Large negative shock\n",
        "\n",
        "returns_df = pd.DataFrame(returns_arr, index=dates, columns=assets)\n",
        "\n",
        "# -------------------------------\n",
        "# Run optimization\n",
        "# -------------------------------\n",
        "weights = np.ones(len(assets)) / len(assets)\n",
        "weights_history = []\n",
        "\n",
        "for t in range(60, len(returns_df)):\n",
        "    asset_returns = returns_df.iloc[t].values\n",
        "    adj_weights = hilbert_cvar_update(weights, asset_returns)\n",
        "    weights = adj_weights\n",
        "    weights_history.append(weights)\n",
        "\n",
        "weights_history = np.array(weights_history)\n",
        "\n",
        "# -------------------------------\n",
        "# Run tests\n",
        "# -------------------------------\n",
        "test_projection(weights_history[-1])\n",
        "test_convergence(weights_history)\n",
        "test_cvar_reduction(returns_df.iloc[-100:].values, np.ones(len(assets)) / len(assets), weights_history[-1])\n",
        "test_smoothness(weights, returns_df.iloc[-1].values)\n",
        "\n",
        "print(\"✅ All heavy-tail stress tests completed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-c9qO_OUgeD",
        "outputId": "a8f6c605-d8c8-4f21-aab7-f45a4a830b8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mean weight change per update: 0.000000\n",
            "✅ Initial CVaR: 0.0499, Final CVaR: 0.0499\n",
            "✅ Approx gradient norm: 0.000000\n",
            "✅ All heavy-tail stress tests completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# Projection operator\n",
        "# -------------------------------\n",
        "def project_simplex(w):\n",
        "    w = np.maximum(w, 1e-5)\n",
        "    w /= np.sum(w)\n",
        "    return w\n",
        "\n",
        "# -------------------------------\n",
        "# Portfolio CVaR\n",
        "# -------------------------------\n",
        "def portfolio_cvar(weights, returns_matrix, alpha=0.05):\n",
        "    portfolio_returns = returns_matrix @ weights\n",
        "    losses = -portfolio_returns\n",
        "    var = np.percentile(losses, 100 * (1 - alpha))\n",
        "    cvar = losses[losses >= var].mean()\n",
        "    return cvar\n",
        "\n",
        "# -------------------------------\n",
        "# Marginal CVaR computation\n",
        "# -------------------------------\n",
        "def compute_marginal_cvar(weights, returns_matrix, alpha=0.05, epsilon=1e-4):\n",
        "    base_cvar = portfolio_cvar(weights, returns_matrix, alpha)\n",
        "    marginal_cvar = np.zeros_like(weights)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        perturbed = weights.copy()\n",
        "        perturbed[i] += epsilon\n",
        "        perturbed = project_simplex(perturbed)\n",
        "        pert_cvar = portfolio_cvar(perturbed, returns_matrix, alpha)\n",
        "        marginal_cvar[i] = (pert_cvar - base_cvar) / epsilon\n",
        "\n",
        "    return marginal_cvar\n",
        "\n",
        "# -------------------------------\n",
        "# Hilbert-enhanced marginal CVaR update\n",
        "# -------------------------------\n",
        "def hilbert_marginal_cvar_update(weights, returns_matrix, alpha=0.05):\n",
        "    marginal_cvar = compute_marginal_cvar(weights, returns_matrix, alpha)\n",
        "    adj = np.exp(-marginal_cvar)\n",
        "    new_w = weights * adj\n",
        "    new_w = project_simplex(new_w)\n",
        "    return new_w\n",
        "\n",
        "# -------------------------------\n",
        "# Tests\n",
        "# -------------------------------\n",
        "def test_projection(weights):\n",
        "    assert np.isclose(np.sum(weights), 1.0, atol=1e-6), \"Weights do not sum to 1\"\n",
        "    assert np.all(weights >= 0), \"Negative weights found\"\n",
        "\n",
        "def test_convergence(weights_history):\n",
        "    diffs = np.abs(np.diff(weights_history, axis=0))\n",
        "    mean_change = np.mean(diffs)\n",
        "    print(f\"✅ Mean weight change per update: {mean_change:.6f}\")\n",
        "\n",
        "def test_cvar_reduction(returns_matrix, weights_initial, weights_final, alpha=0.05):\n",
        "    cvar_init = portfolio_cvar(weights_initial, returns_matrix, alpha)\n",
        "    cvar_final = portfolio_cvar(weights_final, returns_matrix, alpha)\n",
        "    print(f\"✅ Initial CVaR: {cvar_init:.4f}, Final CVaR: {cvar_final:.4f}\")\n",
        "\n",
        "def test_smoothness(weights, returns_matrix, eps=1e-5):\n",
        "    base_value = hilbert_marginal_cvar_update(weights, returns_matrix)\n",
        "    perturbed_weights = weights + eps\n",
        "    perturbed_weights = project_simplex(perturbed_weights)\n",
        "    pert_value = hilbert_marginal_cvar_update(perturbed_weights, returns_matrix)\n",
        "    grad_norm = np.linalg.norm(pert_value - base_value) / eps\n",
        "    print(f\"✅ Approx gradient norm: {grad_norm:.6f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Heavy-tail & shock simulation\n",
        "# -------------------------------\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range(\"2010-01-01\", periods=2520, freq='B')\n",
        "assets = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]\n",
        "\n",
        "# Simulate heavy-tailed returns (t-distributed, df=3)\n",
        "returns_arr = 0.001 + 0.03 * np.random.standard_t(df=3, size=(len(dates), len(assets)))\n",
        "\n",
        "# Inject large negative shocks\n",
        "shock_days = np.random.choice(len(dates), size=10, replace=False)\n",
        "for day in shock_days:\n",
        "    returns_arr[day] -= 0.2\n",
        "\n",
        "returns_df = pd.DataFrame(returns_arr, index=dates, columns=assets)\n",
        "\n",
        "# -------------------------------\n",
        "# Run optimization loop\n",
        "# -------------------------------\n",
        "weights = np.ones(len(assets)) / len(assets)\n",
        "weights_history = []\n",
        "\n",
        "# Use rolling window for marginal CVaR estimates\n",
        "window_size = 60\n",
        "\n",
        "for t in range(window_size, len(returns_df)):\n",
        "    returns_window = returns_df.iloc[t - window_size:t].values\n",
        "    adj_weights = hilbert_marginal_cvar_update(weights, returns_window)\n",
        "    weights = adj_weights\n",
        "    weights_history.append(weights)\n",
        "\n",
        "weights_history = np.array(weights_history)\n",
        "\n",
        "# -------------------------------\n",
        "# Run tests\n",
        "# -------------------------------\n",
        "test_projection(weights_history[-1])\n",
        "test_convergence(weights_history)\n",
        "test_cvar_reduction(returns_df.iloc[-100:].values, np.ones(len(assets)) / len(assets), weights_history[-1])\n",
        "test_smoothness(weights, returns_df.iloc[-60:].values)\n",
        "\n",
        "print(\"✅ All marginal CVaR tests completed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhh9-557VAhX",
        "outputId": "fa920994-5a3d-41e4-9858-1c7779bef055"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mean weight change per update: 0.003912\n",
            "✅ Initial CVaR: 0.0499, Final CVaR: 0.0383\n",
            "✅ Approx gradient norm: 1.103785\n",
            "✅ All marginal CVaR tests completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# Projection operator\n",
        "# -------------------------------\n",
        "def project_simplex(w):\n",
        "    w = np.maximum(w, 1e-5)\n",
        "    w /= np.sum(w)\n",
        "    return w\n",
        "\n",
        "# -------------------------------\n",
        "# Portfolio CVaR\n",
        "# -------------------------------\n",
        "def portfolio_cvar(weights, returns_matrix, alpha=0.05):\n",
        "    portfolio_returns = returns_matrix @ weights\n",
        "    losses = -portfolio_returns\n",
        "    var = np.percentile(losses, 100 * (1 - alpha))\n",
        "    cvar = losses[losses >= var].mean()\n",
        "    return cvar\n",
        "\n",
        "# -------------------------------\n",
        "# Marginal CVaR gradient\n",
        "# -------------------------------\n",
        "def compute_marginal_cvar(weights, returns_matrix, alpha=0.05, epsilon=1e-4):\n",
        "    base_cvar = portfolio_cvar(weights, returns_matrix, alpha)\n",
        "    marginal_cvar = np.zeros_like(weights)\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        perturbed = weights.copy()\n",
        "        perturbed[i] += epsilon\n",
        "        perturbed = project_simplex(perturbed)\n",
        "        pert_cvar = portfolio_cvar(perturbed, returns_matrix, alpha)\n",
        "        marginal_cvar[i] = (pert_cvar - base_cvar) / epsilon\n",
        "\n",
        "    return marginal_cvar\n",
        "\n",
        "# -------------------------------\n",
        "# Continuous-time-inspired update\n",
        "# -------------------------------\n",
        "def continuous_cvar_update(weights, returns_matrix, alpha=0.05, eta=0.01):\n",
        "    grad = compute_marginal_cvar(weights, returns_matrix, alpha)\n",
        "    new_w = weights - eta * grad\n",
        "    new_w = project_simplex(new_w)\n",
        "    return new_w\n",
        "\n",
        "# -------------------------------\n",
        "# Heavy-tail & shock simulation\n",
        "# -------------------------------\n",
        "np.random.seed(42)\n",
        "dates = pd.date_range(\"2010-01-01\", periods=2520, freq='B')\n",
        "assets = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]\n",
        "\n",
        "returns_arr = 0.001 + 0.03 * np.random.standard_t(df=3, size=(len(dates), len(assets)))\n",
        "shock_days = np.random.choice(len(dates), size=10, replace=False)\n",
        "for day in shock_days:\n",
        "    returns_arr[day] -= 0.2\n",
        "\n",
        "returns_df = pd.DataFrame(returns_arr, index=dates, columns=assets)\n",
        "\n",
        "# -------------------------------\n",
        "# Run continuous-time-inspired optimization\n",
        "# -------------------------------\n",
        "weights = np.ones(len(assets)) / len(assets)\n",
        "weights_history = []\n",
        "\n",
        "window_size = 60\n",
        "\n",
        "for t in range(window_size, len(returns_df)):\n",
        "    returns_window = returns_df.iloc[t - window_size:t].values\n",
        "    weights = continuous_cvar_update(weights, returns_window, eta=0.01)\n",
        "    weights_history.append(weights)\n",
        "\n",
        "weights_history = np.array(weights_history)\n",
        "\n",
        "# -------------------------------\n",
        "# Tests\n",
        "# -------------------------------\n",
        "def test_projection(weights):\n",
        "    assert np.isclose(np.sum(weights), 1.0, atol=1e-6), \"Weights do not sum to 1\"\n",
        "    assert np.all(weights >= 0), \"Negative weights found\"\n",
        "\n",
        "def test_convergence(weights_history):\n",
        "    diffs = np.abs(np.diff(weights_history, axis=0))\n",
        "    mean_change = np.mean(diffs)\n",
        "    print(f\"✅ Mean weight change per update: {mean_change:.6f}\")\n",
        "\n",
        "def test_cvar_reduction(returns_matrix, weights_initial, weights_final, alpha=0.05):\n",
        "    cvar_init = portfolio_cvar(weights_initial, returns_matrix, alpha)\n",
        "    cvar_final = portfolio_cvar(weights_final, returns_matrix, alpha)\n",
        "    print(f\"✅ Initial CVaR: {cvar_init:.4f}, Final CVaR: {cvar_final:.4f}\")\n",
        "\n",
        "def test_smoothness(weights, returns_matrix, eps=1e-5):\n",
        "    base_value = continuous_cvar_update(weights, returns_matrix, eta=0.01)\n",
        "    perturbed_weights = weights + eps\n",
        "    perturbed_weights = project_simplex(perturbed_weights)\n",
        "    pert_value = continuous_cvar_update(perturbed_weights, returns_matrix, eta=0.01)\n",
        "    grad_norm = np.linalg.norm(pert_value - base_value) / eps\n",
        "    print(f\"✅ Approx gradient norm: {grad_norm:.6f}\")\n",
        "\n",
        "# Run final tests\n",
        "test_projection(weights_history[-1])\n",
        "test_convergence(weights_history)\n",
        "test_cvar_reduction(returns_df.iloc[-100:].values, np.ones(len(assets)) / len(assets), weights_history[-1])\n",
        "test_smoothness(weights, returns_df.iloc[-60:].values)\n",
        "\n",
        "print(\"✅ All continuous-time-inspired tests completed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKJ6nP8EVLlH",
        "outputId": "3eff6564-4e9f-4e5c-b6fd-3937668f7acc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mean weight change per update: 0.000326\n",
            "✅ Initial CVaR: 0.0499, Final CVaR: 0.0419\n",
            "✅ Approx gradient norm: 0.539012\n",
            "✅ All continuous-time-inspired tests completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5IOgrq_wVZih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}